{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "1. The assignment is done and submitted as groups.\n",
    "2. One representative will upload the submission on Dropbox.\n",
    "3. Make sure you installed all packages that are imported in the file before you run the codes.\n",
    "4. Cheating is not allowed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data project, we will focus on exploratory data analysis of obesity levels.\n",
    "\n",
    "Let's first load all libraries or packages needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 1__\n",
    ">\n",
    ">- Import the data file \"obesity_level.csv\"\n",
    ">- Check metadata using `info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2120 entries, 0 to 2119\n",
      "Data columns (total 20 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   year                            2120 non-null   int64  \n",
      " 1   month                           2120 non-null   int64  \n",
      " 2   day                             2120 non-null   int64  \n",
      " 3   gender                          2111 non-null   object \n",
      " 4   age                             2120 non-null   float64\n",
      " 5   height                          2111 non-null   float64\n",
      " 6   weight                          2111 non-null   float64\n",
      " 7   family_history_with_overweight  2111 non-null   object \n",
      " 8   FAVC                            2111 non-null   object \n",
      " 9   FCVC                            2111 non-null   float64\n",
      " 10  NCP                             2111 non-null   float64\n",
      " 11  CAEC                            2111 non-null   object \n",
      " 12  SMOKE                           2111 non-null   object \n",
      " 13  CH2O                            2111 non-null   float64\n",
      " 14  SCC                             2111 non-null   object \n",
      " 15  FAF                             2111 non-null   float64\n",
      " 16  TUE                             2111 non-null   float64\n",
      " 17  CALC                            2111 non-null   object \n",
      " 18  MTRANS                          2111 non-null   object \n",
      " 19  NObeyesdad                      2111 non-null   object \n",
      "dtypes: float64(8), int64(3), object(9)\n",
      "memory usage: 331.4+ KB\n"
     ]
    }
   ],
   "source": [
    "obs_df = pd.read_csv('obesity_level.csv')\n",
    "obs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 2__\n",
    ">\n",
    ">Check the top 10 rows of the obesity data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>53.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>53.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>68.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  gender   age  height  weight  \\\n",
       "0  2015      9   22  Female  21.0    1.62    64.0   \n",
       "1  2015     10   19  Female  21.0    1.52    56.0   \n",
       "2  2015      1   19    Male  23.0    1.80    77.0   \n",
       "3  2015     11   17    Male  27.0    1.80    87.0   \n",
       "4  2015      2   24    Male  22.0    1.78    89.8   \n",
       "5  2015      5    4    Male  29.0    1.62    53.0   \n",
       "6  2016      2   22  Female  23.0    1.50    55.0   \n",
       "7  2016      8   14    Male  22.0    1.64    53.0   \n",
       "8  2015      4   13    Male  24.0    1.78    64.0   \n",
       "9  2016      5   20    Male  22.0    1.72    68.0   \n",
       "\n",
       "  family_history_with_overweight FAVC  FCVC  NCP       CAEC SMOKE  CH2O  SCC  \\\n",
       "0                            yes   no   2.0  3.0  Sometimes    no   2.0   no   \n",
       "1                            yes   no   3.0  3.0  Sometimes   yes   3.0  yes   \n",
       "2                            yes   no   2.0  3.0  Sometimes    no   2.0   no   \n",
       "3                             no   no   3.0  3.0  Sometimes    no   2.0   no   \n",
       "4                             no   no   2.0  1.0  Sometimes    no   2.0   no   \n",
       "5                             no  yes   2.0  3.0  Sometimes    no   2.0   no   \n",
       "6                            yes  yes   3.0  3.0  Sometimes    no   2.0   no   \n",
       "7                             no   no   2.0  3.0  Sometimes    no   2.0   no   \n",
       "8                            yes  yes   3.0  3.0  Sometimes    no   2.0   no   \n",
       "9                            yes  yes   2.0  3.0  Sometimes    no   2.0   no   \n",
       "\n",
       "   FAF  TUE        CALC                 MTRANS           NObeyesdad  \n",
       "0  0.0  1.0          no  Public_Transportation        Normal_Weight  \n",
       "1  3.0  0.0   Sometimes  Public_Transportation        Normal_Weight  \n",
       "2  2.0  1.0  Frequently  Public_Transportation        Normal_Weight  \n",
       "3  2.0  0.0  Frequently                Walking   Overweight_Level_I  \n",
       "4  0.0  0.0   Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "5  0.0  0.0   Sometimes             Automobile        Normal_Weight  \n",
       "6  1.0  0.0   Sometimes              Motorbike        Normal_Weight  \n",
       "7  3.0  0.0   Sometimes  Public_Transportation        Normal_Weight  \n",
       "8  1.0  1.0  Frequently  Public_Transportation        Normal_Weight  \n",
       "9  1.0  1.0          no  Public_Transportation        Normal_Weight  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you know which columns contain date information? The first three columns (i.e., __year__, __month__, __day__) are integers, shown as `int64` from the metadata above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 3__\n",
    ">\n",
    ">- Combine and convert these three columns to `date` column, which contains `datetime` type\n",
    ">- Confirm the result by printing its data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data type\n",
    "print(obs_df['date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks the date is not read as date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2015-09-22\n",
       "1      2015-10-19\n",
       "2      2015-01-19\n",
       "3      2015-11-17\n",
       "4      2015-02-24\n",
       "          ...    \n",
       "2115   2015-06-26\n",
       "2116   2015-07-22\n",
       "2117   2016-05-04\n",
       "2118   2015-12-02\n",
       "2119   2015-01-25\n",
       "Name: date, Length: 2120, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df['date'] = pd.to_datetime(obs_df[['year', 'month', 'day']])\n",
    "\n",
    "# Call the column to see results\n",
    "obs_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Print data type\n",
    "print(obs_df['date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the last column __NObeyesdad__, which has the obesity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 4__\n",
    ">\n",
    "> Find the unique entries in __NObeyesdad__ column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal_Weight' 'Overweight_Level_I' 'Overweight_Level_II'\n",
      " 'Obesity_Type_I' 'Insufficient_Weight' 'Obesity_Type_II'\n",
      " 'Obesity_Type_III' nan]\n"
     ]
    }
   ],
   "source": [
    "NObeyesdad_Unq = obs_df['NObeyesdad'].unique()\n",
    "print(NObeyesdad_Unq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 5__\n",
    ">\n",
    ">- Print the min and max date in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-27 00:00:00\n",
      "2015-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(obs_df['date'].max())\n",
    "print(obs_df['date'].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find out if there's any missing values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 6__\n",
    ">\n",
    ">- Find the number of missing values in each column\n",
    ">- Retrieve rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                              0\n",
       "month                             0\n",
       "day                               0\n",
       "gender                            9\n",
       "age                               0\n",
       "height                            9\n",
       "weight                            9\n",
       "family_history_with_overweight    9\n",
       "FAVC                              9\n",
       "FCVC                              9\n",
       "NCP                               9\n",
       "CAEC                              9\n",
       "SMOKE                             9\n",
       "CH2O                              9\n",
       "SCC                               9\n",
       "FAF                               9\n",
       "TUE                               9\n",
       "CALC                              9\n",
       "MTRANS                            9\n",
       "NObeyesdad                        9\n",
       "date                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of missing values in columns\n",
    "obs_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  month  day gender   age  height  weight  \\\n",
      "2111  2016      4   24    NaN  22.0     NaN     NaN   \n",
      "2112  2016     10   12    NaN  67.0     NaN     NaN   \n",
      "2113  2015      4   20    NaN  80.0     NaN     NaN   \n",
      "2114  2016      5   21    NaN  19.0     NaN     NaN   \n",
      "2115  2015      6   26    NaN  33.0     NaN     NaN   \n",
      "2116  2015      7   22    NaN  56.0     NaN     NaN   \n",
      "2117  2016      5    4    NaN  32.0     NaN     NaN   \n",
      "2118  2015     12    2    NaN  94.0     NaN     NaN   \n",
      "2119  2015      1   25    NaN  71.0     NaN     NaN   \n",
      "\n",
      "     family_history_with_overweight FAVC  FCVC  ...  CAEC SMOKE CH2O  SCC FAF  \\\n",
      "2111                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2112                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2113                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2114                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2115                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2116                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2117                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2118                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "2119                            NaN  NaN   NaN  ...   NaN   NaN  NaN  NaN NaN   \n",
      "\n",
      "      TUE  CALC MTRANS NObeyesdad       date  \n",
      "2111  NaN   NaN    NaN        NaN 2016-04-24  \n",
      "2112  NaN   NaN    NaN        NaN 2016-10-12  \n",
      "2113  NaN   NaN    NaN        NaN 2015-04-20  \n",
      "2114  NaN   NaN    NaN        NaN 2016-05-21  \n",
      "2115  NaN   NaN    NaN        NaN 2015-06-26  \n",
      "2116  NaN   NaN    NaN        NaN 2015-07-22  \n",
      "2117  NaN   NaN    NaN        NaN 2016-05-04  \n",
      "2118  NaN   NaN    NaN        NaN 2015-12-02  \n",
      "2119  NaN   NaN    NaN        NaN 2015-01-25  \n",
      "\n",
      "[9 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve missing values in rows\n",
    "missing_rows = obs_df[obs_df.isnull().any(axis=1)]\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some records only contain age data on file and have missing values in all the other essential columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Task 7__\n",
    ">\n",
    "> Handle missing values. What is your suggestion? Removing all rows with NA or removing the column if it has NA? One is the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = obs_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [year, month, day, gender, age, height, weight, family_history_with_overweight, FAVC, FCVC, NCP, CAEC, SMOKE, CH2O, SCC, FAF, TUE, CALC, MTRANS, NObeyesdad, date]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the number of missing variables again\n",
    "missing_rows = obs_df[obs_df.isnull().any(axis=1)]\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we want to find out if there's any duplicated values. Note that this data set does not have an id column. So, we need to be cautious and infer duplicates by including ALL the values (not just a few columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 8__\n",
    ">\n",
    ">Check if there is any duplicates in the data set. Do you need to remove duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(obs_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data more. Most of the columns in the data set describe the attributes of eating habits and physical conditions, i.e., __FAVC__, __FCVC__, __NCP__, __CAEC__, __SMOKE__, __CH2O__, __SCC__, __FAF__, __TUE__, __CALC__, __MTRANS__. We will dive into a few attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 9__\n",
    ">\n",
    ">- Check the min, max, and average values of the __age__ column\n",
    ">- Find out how many data points are in each gender group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n",
      "14.0\n",
      "24.312599908574136\n"
     ]
    }
   ],
   "source": [
    "# Check values\n",
    "print(obs_df['age'].max())\n",
    "print(obs_df['age'].min())\n",
    "print(obs_df['age'].sum()/obs_df['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Male      1068\n",
      "Female    1043\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count values\n",
    "print(obs_df['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 10__\n",
    ">\n",
    ">- Find out what are the values and the corresponding counts in the __NObeyesdad__ column. Is it a ordinal or nominal variable?\n",
    ">   - You can count the values in the column\n",
    ">   - It seems like there is an order between different levels of obesity, ain't it?\n",
    ">- Depending on which is the correct variable type (nominal or ordinal) convert the `NObesity_encoded` column to numeric using an encoder or map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NObeyesdad\n",
      "Obesity_Type_I         351\n",
      "Obesity_Type_III       324\n",
      "Obesity_Type_II        297\n",
      "Overweight_Level_I     290\n",
      "Overweight_Level_II    290\n",
      "Normal_Weight          287\n",
      "Insufficient_Weight    272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count values\n",
    "print(obs_df['NObeyesdad'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "ordinal_mapping  = {\n",
    "    'Obesity_Type_I':         4,\n",
    "    'Obesity_Type_III':       6,\n",
    "    'Obesity_Type_II' :       5,\n",
    "    'Overweight_Level_I':     2,\n",
    "    'Overweight_Level_II':    3,\n",
    "    'Normal_Weight':          1,\n",
    "    'Insufficient_Weight':    0\n",
    "}\n",
    "\n",
    "obs_df[\"NObeyesdad\"] = obs_df[\"NObeyesdad\"].map(ordinal_mapping)\n",
    "\n",
    "print(obs_df['NObeyesdad'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 11__\n",
    ">\n",
    ">- Check the values of __CAEC__ (consumption of food between meals) and __CALC__ (consumption of alcohol). Do they have same categorical values?\n",
    ">- Convert each of the two variables to numeric: `CAEC_encoded` and `CALC_encoded`. Pay attention to the ordinal or nominal type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check the values of CAEC\n",
    "print(obs_df['CAEC'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check the values of CALC \n",
    "print(obs_df['CALC'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAEC_encoded = {\n",
    "    'no': 0,\n",
    "    'Sometimes': 1,\n",
    "    'Frequently': 2,\n",
    "    'Always': 3\n",
    "}\n",
    "\n",
    "CALC_encoded = {\n",
    "    'no': 0,\n",
    "    'Sometimes': 1,\n",
    "    'Frequently': 2,\n",
    "    'Always': 3\n",
    "}\n",
    "obs_df[\"CAEC_encoded\"] = obs_df[\"CAEC\"].map(CAEC_encoded)\n",
    "obs_df[\"CALC_encoded\"] = obs_df[\"CALC\"].map(CALC_encoded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check whether the encoding works\n",
    "print(obs_df['CAEC_encoded'].value_counts().sort_index())\n",
    "print(obs_df['CALC_encoded'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 12__\n",
    ">\n",
    ">- Check the values of transportation used (__MTRANS__ column). It is nominal variable.\n",
    ">- Convert it to numeric using one-hot encoding and use the value as the new column names, e.g., `Automobile` and `Bike`. Hint: you can use either `get_dummies` from pandas or `OneHotEncoder` from sklearn. The latter will require some extra steps to merge back to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values\n",
    "print(obs_df['MTRANS'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several binary variables in the dataset: __family_history_with_overweight__, __FAVC__ (frequency of consumption of vegetables), __SMOKE__, __SCC__ (calories consumption monitoring). Let's transform these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 13__\n",
    ">\n",
    ">- Check the values of __family_history_with_overweight__, __FAVC__, __SMOKE__, __SCC__ \n",
    ">- Convert them to numeric with 1 for `yes` and 0 for `no`. The new columns are names with suffix `_encoded`, e.g., `family_history_with_overweight_encoded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric\n",
    "binary_encoding_map = {'yes':1, 'no':0}\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following `for` loop to check the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 14__\n",
    ">\n",
    ">Retrieve rows where values are outliers in the __weight__ column\n",
    ">\n",
    ">- Calculate mean, 3 std above the mean and 3 std below the mean \n",
    ">- Create a filter (a boolean vector) that returns true if values are less than `mean-3*sd` or greater than `mean+3*sd`\n",
    ">- Use this filter to retrieve the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the upper bound, mean, and lower bound\n",
    "weight = ...\n",
    "mean   = ...\n",
    "sd     = ...\n",
    "\n",
    "print(..., ..., ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter and retrieve the outliers\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the same method to find out outliers in the other columns. But there's a easier way to find out all in once using the `for` loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 15__\n",
    ">\n",
    ">Split the data set into 80% train set and 20% test set\n",
    ">\n",
    ">- The target variable is __NObesity_encoded__\n",
    ">- The feature columns are __age__, __height__, __weight__, __FCVC__, __NCP__, __CH2O__, __CAEC_encoded__, __CALC_encoded__, __Automobile__, __Bike__, __Motorbike__, __Public_Transportation__, __Walking__, __family_history_with_overweight_encoded__, __FAVC_encoded__, __SMOKE_encoded__, __SCC_encoded__\n",
    ">\n",
    ">Remember our target variable has multiple categories? Do you need to consider stratified splitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target_var = 'NObesity_encoded'\n",
    "feature_var = ['age', 'height', 'weight', 'FCVC', 'NCP', 'CH2O', 'CAEC_encoded', 'CALC_encoded',\n",
    "               'Automobile', 'Bike', 'Motorbike', 'Public_Transportation', 'Walking',\n",
    "               'family_history_with_overweight_encoded', 'FAVC_encoded', 'SMOKE_encoded', 'SCC_encoded'] \n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the target var distribution in train set vs test set\n",
    "print(y_train.value_counts(), y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 16__\n",
    ">\n",
    ">- Apply `MinMaxScaler` to scale columns __age__, __height__, __weight__, __FCVC__, __NCP__, __CH2O__ between 0 and 1. Do you need to scale the encoded categorical variables?\n",
    ">- Implement the scaler to both train and test sets from the above task. Hint: you can assign the scaled value to `X_train[cols]` and `X_test[cols]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the scaler will need to fit to train set\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "...\n",
    "scale_cols = ['age', 'height', 'weight', 'FCVC', 'NCP', 'CH2O']\n",
    "...\n",
    "\n",
    "# Transform both train and test sets\n",
    "X_train[scale_cols] = ...\n",
    "X_test[scale_cols]  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,summarize , poly)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Boston Data\n",
    "boston = load_data(\"Boston\") \n",
    "boston.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [Kaggle page](https://www.kaggle.com/datasets/avish5787/boston-data-set), below you can find the details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRIM - per capita crime rate by town\n",
    "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS - proportion of non-retail business acres per town.\n",
    "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- NOX - nitric oxides concentration (parts per 10 million)\n",
    "- RM - average number of rooms per dwelling\n",
    "- AGE - proportion of owner-occupied units built prior to 1940\n",
    "- DIS - weighted distances to five Boston employment centres\n",
    "- RAD - index of accessibility to radial highways\n",
    "- TAX - full-value property-tax rate per \\$10,000\n",
    "- PTRATIO - pupil-teacher ratio by town\n",
    "- B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT - \\% lower status of the population\n",
    "- MEDV - Median value of owner-occupied homes in \\$1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 17__\n",
    ">\n",
    "> Give a first look at your data. Print how many row/columns in the data, print the first 5 rows and use .info to learn more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row/column counts\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 row\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 18__\n",
    ">\n",
    "> Using seaborn package, plot the scatterplot of the data. On map `lstat` on x axis and `medv` on y axis. Use `hue` option to map `indus` to colour and `style` option to map `chas` to style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks there is negative correlation between the median value of houses \\% of lower status of the population. Also as colours suggest, as the proportion of industrial residences increase price reduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 19__\n",
    ">\n",
    "> - Apply train test split to the data. Use 'medv' as output (y) values and everything else as input variables.\n",
    "> - The test size must be 20% of the data.\n",
    "> - Set randomm state to 156."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = ...\n",
    "X = boston.drop(['medv'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code fits a simple linear regression to model the relationship between `lstat` and `medv` and plots the model.\n",
    "- First we initiate the model\n",
    "- Then fit the model on train set\n",
    "- And finally calculate the test set (MAE and MSE) performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Initiate the model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit \n",
    "lm = lm.fit(X_train[['lstat']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated coefficients are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatterplot\n",
    "sns.scatterplot(data=boston, x=\"lstat\", y=\"medv\")\n",
    "\n",
    "# Add predictions\n",
    "preds = lm.predict(X[['lstat']])\n",
    "\n",
    "plt.plot(X[['lstat']],preds,c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "# Calculate the predictions on test set\n",
    "preds = lm.predict(X_test[['lstat']])\n",
    "\n",
    "print('MAE (test): ',metrics.mean_absolute_error(y_test,preds))\n",
    "print('MSE (test): ',metrics.mean_squared_error(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 20__\n",
    ">\n",
    "> - Fit a multi-linear regression. Use `['lstat','rm', 'nox']` as independent (input) variables and `medv` as dependent (output)\n",
    "> - Fit the model on train set\n",
    "> - Print the model coefficients\n",
    "> - Calculate the predictions on test set\n",
    "> - Print the test set MAE and MSE.\n",
    "> - Does the mean absolute and mean squarred errors reduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate and fit a Linear Regression model\n",
    "...\n",
    "\n",
    "# Predict on test set\n",
    "...\n",
    "\n",
    "# Calculate performance\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression\n",
    "\n",
    "Polynomian regressions are nonlinear models that are trained using the same way that linear models are trained. Only difference is, instead of just inputting the features (independent variables) themselves, we also calculate their powers (square, cube, 4th degree etc) and input the model.\n",
    "\n",
    "Let's train a 4th-degree polynomial regression using only `lstat` as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly    = PolynomialFeatures (degree=4, include_bias=False)\n",
    "x_trn   = poly.fit_transform(X_train['lstat'].to_numpy().reshape(-1,1))\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm = lm.fit(x_trn, y_train)\n",
    "\n",
    "x     = poly.transform(X['lstat'].to_numpy().reshape(-1,1))\n",
    "preds = lm.predict(x)\n",
    "\n",
    "# Plot the scatterplot\n",
    "sns.scatterplot(data=boston, x=\"lstat\", y=\"medv\")\n",
    "\n",
    "# Add predictions\n",
    "plt.scatter(X[['lstat']],preds,c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above the predictions are not linear but can be 4th degree polynomial function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 21__\n",
    ">\n",
    "> - Complete the below code that fits polynomial regression with degree = 1,2,...,12 iteratively on train set and calculate the test set performance. Remember that in Python range(a,b) generates the series [a,a+1,...,b-1].\n",
    "> - The test MSE calculations are collected in a list, `MSEs`\n",
    "> - Plot the MSE against the degree of the polynomial regression.\n",
    "> - Which polynomial degree minimizes the test loss?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "MSEs = []\n",
    "# Fit model and collect performance iteratively\n",
    "for i in range(1,...):\n",
    "    # Fit a Linear Regression model\n",
    "    poly    = ...\n",
    "    ...\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # Predict on test set\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    # Calculate performance\n",
    "    mse = metrics.mean_squared_error(y_test,preds)\n",
    "    MSEs.append(mse)\n",
    "    print('MSE (test): ', mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the MSE against the degree of the polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(...,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
